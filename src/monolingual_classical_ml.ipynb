{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forza Motorsport is a popular racing game that...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buying Virtual Console games for your Nintendo...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Windows NT 4.0 was a popular operating system ...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to Make Perfume\\n\\nPerfume is a great way ...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to Convert Song Lyrics to a Song'\\n\\nConve...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119752</th>\n",
       "      <td>The paper is an interesting contribution, prim...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119753</th>\n",
       "      <td>\\nWe thank the reviewers for all their comment...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119754</th>\n",
       "      <td>The authors introduce a semi-supervised method...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119755</th>\n",
       "      <td>This paper proposes the Neural Graph Machine t...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119756</th>\n",
       "      <td>The paper proposes a model that aims at learni...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119757 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0       Forza Motorsport is a popular racing game that...    LLM\n",
       "1       Buying Virtual Console games for your Nintendo...    LLM\n",
       "2       Windows NT 4.0 was a popular operating system ...    LLM\n",
       "3       How to Make Perfume\\n\\nPerfume is a great way ...    LLM\n",
       "4       How to Convert Song Lyrics to a Song'\\n\\nConve...    LLM\n",
       "...                                                   ...    ...\n",
       "119752  The paper is an interesting contribution, prim...  human\n",
       "119753  \\nWe thank the reviewers for all their comment...  human\n",
       "119754  The authors introduce a semi-supervised method...  human\n",
       "119755  This paper proposes the Neural Graph Machine t...  human\n",
       "119756  The paper proposes a model that aims at learni...  human\n",
       "\n",
       "[119757 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from language_tool_python import LanguageTool\n",
    "import helpers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "train_path = \"data/SemEval2024-Task8/SubtaskA/subtaskA_train_monolingual.jsonl\"\n",
    "val_path = \"data/SemEval2024-Task8/SubtaskA/subtaskA_dev_monolingual.jsonl\"\n",
    "train_addon1_path = \"./backtranslation_data_mono/mono_addon1.jsonl\"\n",
    "train_addon2_path = \"./backtranslation_data_mono/mono_addon2.jsonl\"\n",
    "train_addon3_path = \"./backtranslation_data_mono/mono_addon3.jsonl\"\n",
    "\n",
    "train_df, val_df = helpers.get_pandas_dfs(train_path, val_path)\n",
    "# train_addon1_df = helpers.get_pandas_atomic_dfs(train_addon1_path)\n",
    "# train_addon2_df = helpers.get_pandas_atomic_dfs(train_addon2_path)\n",
    "# train_addon3_df = helpers.get_pandas_atomic_dfs(train_addon3_path)\n",
    "\n",
    "# train_df = pd.concat([train_df, train_addon1_df, train_addon2_df, train_addon3_df], axis=0, ignore_index=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>std_words_per_sentence</th>\n",
       "      <th>num_words</th>\n",
       "      <th>average_words_per_sentence</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>num_digits</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>other_characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forza Motorsport is a popular racing game that...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>38</td>\n",
       "      <td>8.394572</td>\n",
       "      <td>410</td>\n",
       "      <td>10.789474</td>\n",
       "      <td>4.224390</td>\n",
       "      <td>15</td>\n",
       "      <td>82</td>\n",
       "      <td>1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buying Virtual Console games for your Nintendo...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>69</td>\n",
       "      <td>7.245130</td>\n",
       "      <td>693</td>\n",
       "      <td>10.043478</td>\n",
       "      <td>4.151515</td>\n",
       "      <td>30</td>\n",
       "      <td>132</td>\n",
       "      <td>2873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Windows NT 4.0 was a popular operating system ...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>110</td>\n",
       "      <td>7.022920</td>\n",
       "      <td>939</td>\n",
       "      <td>8.536364</td>\n",
       "      <td>4.412141</td>\n",
       "      <td>79</td>\n",
       "      <td>153</td>\n",
       "      <td>4066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to Make Perfume\\n\\nPerfume is a great way ...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>68</td>\n",
       "      <td>7.833806</td>\n",
       "      <td>810</td>\n",
       "      <td>11.911765</td>\n",
       "      <td>4.572840</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "      <td>3749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to Convert Song Lyrics to a Song'\\n\\nConve...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>43</td>\n",
       "      <td>11.794435</td>\n",
       "      <td>585</td>\n",
       "      <td>13.604651</td>\n",
       "      <td>4.135043</td>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>2412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119752</th>\n",
       "      <td>The paper is an interesting contribution, prim...</td>\n",
       "      <td>human</td>\n",
       "      <td>5</td>\n",
       "      <td>9.620811</td>\n",
       "      <td>73</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>4.904110</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119753</th>\n",
       "      <td>\\nWe thank the reviewers for all their comment...</td>\n",
       "      <td>human</td>\n",
       "      <td>65</td>\n",
       "      <td>9.448008</td>\n",
       "      <td>766</td>\n",
       "      <td>11.784615</td>\n",
       "      <td>4.870757</td>\n",
       "      <td>155</td>\n",
       "      <td>262</td>\n",
       "      <td>3654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119754</th>\n",
       "      <td>The authors introduce a semi-supervised method...</td>\n",
       "      <td>human</td>\n",
       "      <td>10</td>\n",
       "      <td>7.736278</td>\n",
       "      <td>176</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>5.079545</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119755</th>\n",
       "      <td>This paper proposes the Neural Graph Machine t...</td>\n",
       "      <td>human</td>\n",
       "      <td>15</td>\n",
       "      <td>11.999259</td>\n",
       "      <td>203</td>\n",
       "      <td>13.533333</td>\n",
       "      <td>4.655172</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119756</th>\n",
       "      <td>The paper proposes a model that aims at learni...</td>\n",
       "      <td>human</td>\n",
       "      <td>14</td>\n",
       "      <td>9.926259</td>\n",
       "      <td>172</td>\n",
       "      <td>12.285714</td>\n",
       "      <td>4.953488</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119757 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label  \\\n",
       "0       Forza Motorsport is a popular racing game that...    LLM   \n",
       "1       Buying Virtual Console games for your Nintendo...    LLM   \n",
       "2       Windows NT 4.0 was a popular operating system ...    LLM   \n",
       "3       How to Make Perfume\\n\\nPerfume is a great way ...    LLM   \n",
       "4       How to Convert Song Lyrics to a Song'\\n\\nConve...    LLM   \n",
       "...                                                   ...    ...   \n",
       "119752  The paper is an interesting contribution, prim...  human   \n",
       "119753  \\nWe thank the reviewers for all their comment...  human   \n",
       "119754  The authors introduce a semi-supervised method...  human   \n",
       "119755  This paper proposes the Neural Graph Machine t...  human   \n",
       "119756  The paper proposes a model that aims at learni...  human   \n",
       "\n",
       "        num_sentences  std_words_per_sentence  num_words  \\\n",
       "0                  38                8.394572        410   \n",
       "1                  69                7.245130        693   \n",
       "2                 110                7.022920        939   \n",
       "3                  68                7.833806        810   \n",
       "4                  43               11.794435        585   \n",
       "...               ...                     ...        ...   \n",
       "119752              5                9.620811         73   \n",
       "119753             65                9.448008        766   \n",
       "119754             10                7.736278        176   \n",
       "119755             15               11.999259        203   \n",
       "119756             14                9.926259        172   \n",
       "\n",
       "        average_words_per_sentence  average_word_length  num_digits  \\\n",
       "0                        10.789474             4.224390          15   \n",
       "1                        10.043478             4.151515          30   \n",
       "2                         8.536364             4.412141          79   \n",
       "3                        11.911765             4.572840          18   \n",
       "4                        13.604651             4.135043           9   \n",
       "...                            ...                  ...         ...   \n",
       "119752                   14.600000             4.904110           2   \n",
       "119753                   11.784615             4.870757         155   \n",
       "119754                   17.600000             5.079545          24   \n",
       "119755                   13.533333             4.655172          13   \n",
       "119756                   12.285714             4.953488           8   \n",
       "\n",
       "        num_punctuations  other_characters  \n",
       "0                     82              1737  \n",
       "1                    132              2873  \n",
       "2                    153              4066  \n",
       "3                    152              3749  \n",
       "4                     89              2412  \n",
       "...                  ...               ...  \n",
       "119752                14               351  \n",
       "119753               262              3654  \n",
       "119754                37               872  \n",
       "119755                25               935  \n",
       "119756                35               850  \n",
       "\n",
       "[119757 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_statistics(row):\n",
    "    text = row[\"text\"]\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    words_per_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "    std_words_per_sentence = np.std(words_per_sentence)\n",
    "    num_sentences = len(sentences)\n",
    "\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    \n",
    "    num_words = len(words)\n",
    "    num_characters = len(''.join(words))\n",
    "\n",
    "    avg_word_length = num_characters / num_words if num_words > 0 else 0\n",
    "    num_digits = sum(c.isdigit() for c in text)\n",
    "\n",
    "    num_punctuations = sum(c in string.punctuation for c in text)\n",
    "\n",
    "    num_other_characters = len(text) - num_words - num_punctuations - num_digits\n",
    "\n",
    "    avg_words_per_sentence = num_words / num_sentences if num_sentences > 0 else 0\n",
    "\n",
    "    row[\"num_sentences\"] = num_sentences\n",
    "    row[\"std_words_per_sentence\"] = std_words_per_sentence\n",
    "    row[\"num_words\"] = num_words\n",
    "    row[\"average_words_per_sentence\"] = avg_words_per_sentence\n",
    "    row[\"average_word_length\"] = avg_word_length\n",
    "    row[\"num_digits\"] = num_digits\n",
    "    row[\"num_punctuations\"] = num_punctuations\n",
    "    row[\"other_characters\"] = num_other_characters\n",
    "\n",
    "    return row\n",
    "\n",
    "train_df = train_df.apply(text_statistics, axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>std_words_per_sentence</th>\n",
       "      <th>num_words</th>\n",
       "      <th>average_words_per_sentence</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>num_digits</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>other_characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giving gifts should always be enjoyable.  Howe...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>11</td>\n",
       "      <td>14.399265</td>\n",
       "      <td>191</td>\n",
       "      <td>17.363636</td>\n",
       "      <td>4.769634</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yveltal (Japanese: ユベルタル) is one of the main a...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>16</td>\n",
       "      <td>6.872727</td>\n",
       "      <td>181</td>\n",
       "      <td>11.312500</td>\n",
       "      <td>4.060773</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you'd rather not annoy others by being rude...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>25</td>\n",
       "      <td>6.223311</td>\n",
       "      <td>168</td>\n",
       "      <td>6.720000</td>\n",
       "      <td>4.452381</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're interested in visiting gravesite(s) ...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>18</td>\n",
       "      <td>13.348140</td>\n",
       "      <td>219</td>\n",
       "      <td>12.166667</td>\n",
       "      <td>5.082192</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The following are some tips for becoming succe...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>23</td>\n",
       "      <td>5.619975</td>\n",
       "      <td>173</td>\n",
       "      <td>7.521739</td>\n",
       "      <td>4.670520</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>The paper deals with an interesting applicatio...</td>\n",
       "      <td>human</td>\n",
       "      <td>22</td>\n",
       "      <td>13.336708</td>\n",
       "      <td>432</td>\n",
       "      <td>19.636364</td>\n",
       "      <td>4.594907</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>This manuscript tries to tackle neural network...</td>\n",
       "      <td>human</td>\n",
       "      <td>17</td>\n",
       "      <td>16.208631</td>\n",
       "      <td>395</td>\n",
       "      <td>23.235294</td>\n",
       "      <td>4.868354</td>\n",
       "      <td>22</td>\n",
       "      <td>63</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>The paper introduced a regularization scheme t...</td>\n",
       "      <td>human</td>\n",
       "      <td>15</td>\n",
       "      <td>6.331579</td>\n",
       "      <td>130</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>4.807692</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Inspired by the analysis on the effect of the ...</td>\n",
       "      <td>human</td>\n",
       "      <td>16</td>\n",
       "      <td>8.365666</td>\n",
       "      <td>291</td>\n",
       "      <td>18.187500</td>\n",
       "      <td>5.360825</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>\\n- You definitely need to report misclassific...</td>\n",
       "      <td>human</td>\n",
       "      <td>26</td>\n",
       "      <td>8.521206</td>\n",
       "      <td>321</td>\n",
       "      <td>12.346154</td>\n",
       "      <td>4.856698</td>\n",
       "      <td>19</td>\n",
       "      <td>84</td>\n",
       "      <td>1546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  num_sentences  \\\n",
       "0     Giving gifts should always be enjoyable.  Howe...    LLM             11   \n",
       "1     Yveltal (Japanese: ユベルタル) is one of the main a...    LLM             16   \n",
       "2     If you'd rather not annoy others by being rude...    LLM             25   \n",
       "3     If you're interested in visiting gravesite(s) ...    LLM             18   \n",
       "4     The following are some tips for becoming succe...    LLM             23   \n",
       "...                                                 ...    ...            ...   \n",
       "4995  The paper deals with an interesting applicatio...  human             22   \n",
       "4996  This manuscript tries to tackle neural network...  human             17   \n",
       "4997  The paper introduced a regularization scheme t...  human             15   \n",
       "4998  Inspired by the analysis on the effect of the ...  human             16   \n",
       "4999  \\n- You definitely need to report misclassific...  human             26   \n",
       "\n",
       "      std_words_per_sentence  num_words  average_words_per_sentence  \\\n",
       "0                  14.399265        191                   17.363636   \n",
       "1                   6.872727        181                   11.312500   \n",
       "2                   6.223311        168                    6.720000   \n",
       "3                  13.348140        219                   12.166667   \n",
       "4                   5.619975        173                    7.521739   \n",
       "...                      ...        ...                         ...   \n",
       "4995               13.336708        432                   19.636364   \n",
       "4996               16.208631        395                   23.235294   \n",
       "4997                6.331579        130                    8.666667   \n",
       "4998                8.365666        291                   18.187500   \n",
       "4999                8.521206        321                   12.346154   \n",
       "\n",
       "      average_word_length  num_digits  num_punctuations  other_characters  \n",
       "0                4.769634           0                29               925  \n",
       "1                4.060773           1                26               778  \n",
       "2                4.452381          11                33               785  \n",
       "3                5.082192           2                42              1112  \n",
       "4                4.670520           0                51               821  \n",
       "...                   ...         ...               ...               ...  \n",
       "4995             4.594907           7                67              1980  \n",
       "4996             4.868354          22                63              1887  \n",
       "4997             4.807692          21                28               606  \n",
       "4998             5.360825          11                36              1557  \n",
       "4999             4.856698          19                84              1546  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = val_df.apply(text_statistics, axis=1)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1, 3), stop_words='english', max_features = 30000)\n",
    "tf_idf_feats = tf_idf_vect.fit_transform(train_df[\"text\"])\n",
    "other_feats = train_df.drop(columns=[\"text\", \"label\"]).to_numpy()\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df[\"label\"])\n",
    "X_train = hstack((tf_idf_feats, csr_matrix(other_feats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_feats = tf_idf_vect.transform(val_df[\"text\"])\n",
    "other_feats = val_df.drop(columns=[\"text\", \"label\"]).to_numpy()\n",
    "y_val = le.transform(val_df[\"label\"])\n",
    "X_val = hstack((tf_idf_feats, csr_matrix(other_feats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.63123\n",
      "[1]\tvalidation_0-logloss:0.60754\n",
      "[2]\tvalidation_0-logloss:0.57903\n",
      "[3]\tvalidation_0-logloss:0.56282\n",
      "[4]\tvalidation_0-logloss:0.55411\n",
      "[5]\tvalidation_0-logloss:0.54748\n",
      "[6]\tvalidation_0-logloss:0.54909\n",
      "[7]\tvalidation_0-logloss:0.54724\n",
      "[8]\tvalidation_0-logloss:0.54575\n",
      "[9]\tvalidation_0-logloss:0.54114\n",
      "[10]\tvalidation_0-logloss:0.53842\n",
      "[11]\tvalidation_0-logloss:0.54172\n",
      "[12]\tvalidation_0-logloss:0.53525\n",
      "[13]\tvalidation_0-logloss:0.53364\n",
      "[14]\tvalidation_0-logloss:0.53227\n",
      "[15]\tvalidation_0-logloss:0.53135\n",
      "[16]\tvalidation_0-logloss:0.52976\n",
      "[17]\tvalidation_0-logloss:0.53180\n",
      "[18]\tvalidation_0-logloss:0.53229\n",
      "[19]\tvalidation_0-logloss:0.52369\n",
      "[20]\tvalidation_0-logloss:0.52451\n",
      "[21]\tvalidation_0-logloss:0.52226\n",
      "[22]\tvalidation_0-logloss:0.52223\n",
      "[23]\tvalidation_0-logloss:0.51903\n",
      "[24]\tvalidation_0-logloss:0.51839\n",
      "[25]\tvalidation_0-logloss:0.51920\n",
      "[26]\tvalidation_0-logloss:0.52708\n",
      "[27]\tvalidation_0-logloss:0.52663\n",
      "[28]\tvalidation_0-logloss:0.52316\n",
      "[29]\tvalidation_0-logloss:0.52200\n",
      "[30]\tvalidation_0-logloss:0.52085\n",
      "[31]\tvalidation_0-logloss:0.52091\n",
      "[32]\tvalidation_0-logloss:0.52094\n",
      "[33]\tvalidation_0-logloss:0.51400\n",
      "[34]\tvalidation_0-logloss:0.51509\n",
      "[35]\tvalidation_0-logloss:0.51420\n",
      "[36]\tvalidation_0-logloss:0.51340\n",
      "[37]\tvalidation_0-logloss:0.51093\n",
      "[38]\tvalidation_0-logloss:0.51243\n",
      "[39]\tvalidation_0-logloss:0.51331\n",
      "[40]\tvalidation_0-logloss:0.51511\n",
      "[41]\tvalidation_0-logloss:0.51755\n",
      "[42]\tvalidation_0-logloss:0.51832\n",
      "[43]\tvalidation_0-logloss:0.51887\n",
      "[44]\tvalidation_0-logloss:0.52346\n",
      "[45]\tvalidation_0-logloss:0.52225\n",
      "[46]\tvalidation_0-logloss:0.52121\n",
      "XGB metrics: {'accuracy': 0.7354, 'precision': 0.6950613191912496, 'recall': 0.8388, 'f1_score': 0.7601957585644372}\n"
     ]
    }
   ],
   "source": [
    "scale_pos_weight =  sum((~y_train.astype(bool)).astype(int)) / sum(y_train)\n",
    "early_stop = xgboost.callback.EarlyStopping(\n",
    "    rounds=10, metric_name='logloss', save_best=True\n",
    ")\n",
    "xgb = xgboost.XGBClassifier(learning_rate=0.3, n_estimators=500, callbacks=[early_stop], scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "y_pred = xgb.predict(X_val) \n",
    "print(f\"XGB metrics: {helpers.calculate_metrics(y_val, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier metrics: {'accuracy': 0.7242, 'precision': 0.6754303599374022, 'recall': 0.8632, 'f1_score': 0.757857769973661}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")\n",
    "xgboost = XGBClassifier(learning_rate=0.3, n_estimators=100, random_state=42, scale_pos_weight=scale_pos_weight)\n",
    "xgb_random_forest = XGBRFClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('random_forest', random_forest),\n",
    "        ('xgb_classifier', xgboost),\n",
    "        ('xgb_rf_classifier', xgb_random_forest)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "y_pred = voting_classifier.predict(X_val) \n",
    "print(f\"Voting Classifier metrics: {helpers.calculate_metrics(y_val, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
